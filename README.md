# ğŸ§  RAG Chatbot

A Retrieval-Augmented Generation (RAG) chatbot built using Django REST Framework + LangChain + Groq API backend with a React + TypeScript frontend, powered by FAISS vector database and HuggingFace embeddings. This project allows you to ask questions about your API documentation and get precise answers using advanced language models.

## ğŸ“¦ Features
- ğŸ” Ask questions based on your internal API docs
- ğŸ§© Uses vector search to retrieve relevant context
- ğŸ¤– Queries Groq LLMs for precise answers
- ğŸ–¥ï¸ Clean, full-screen chat interface
- ğŸ“œ Maintains conversation history in session

## âš™ï¸ Tech Stack

| Layer           | Stack                                      |
|-----------------|--------------------------------------------|
| **Backend**     | Django, DRF, LangChain, FAISS, Groq API    |
| **Embedding**   | SentenceTransformers (MiniLM)              |
| **Frontend**    | React, Vite, TypeScript, Tailwind, ShadCN  |
| **Vector DB**   | FAISS                                      |

## ğŸš€ Quick Start

### ğŸ”§ Backend Setup

```bash
# 1. Create virtual environment
python -m venv venv && source venv/bin/activate  # Linux/macOS
# OR for Windows:
.\venv\Scripts\activate

# 2. Install dependencies
pip install -r requirements.txt

# 3. Run database migrations
python manage.py migrate

# 4. Start development server
python manage.py runserver
âš ï¸ Important: Create a .env file in the backend directory with your Groq API key:

env
GROQ_API_KEY=your_groq_key_here
ğŸ§ª Frontend Setup
bash
# 1. Install dependencies
npm install

# 2. Start development server
npm run dev
Frontend: http://localhost:5173

Backend: http://127.0.0.1:8000

ğŸ§© RAG Workflow
Document Processing
README.md is split into semantic chunks

Embedding Generation
Chunks are embedded using SentenceTransformers (MiniLM)

Vector Storage
Embeddings stored in FAISS vector database

Query Handling
User question â†’ FAISS retrieves relevant context

LLM Processing
Context + question sent to Groq language model

Response Generation
Precise answer returned via API

ğŸ–¼ï¸ UI Highlights
Full-screen responsive chat layout

Sticky bottom input field

Scrollable conversation history

Clean sidebar navigation

Modern shadcn/ui components

Type-safe TypeScript implementation

ğŸ“ Project Structure
text
backend/
â”œâ”€â”€ chatbot/
â”‚   â”œâ”€â”€ views.py         # API endpoints
â”‚   â”œâ”€â”€ qa_chain.py      # LangChain processing
â”‚   â”œâ”€â”€ faiss_index/     # Vector database
â”‚   â””â”€â”€ utils.py         # Helper functions
â”œâ”€â”€ rag_bot/
â”‚   â”œâ”€â”€ settings.py      # Django configuration
â”‚   â””â”€â”€ urls.py          # URL routing
â””â”€â”€ manage.py            # Django CLI

frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/      # React components
â”‚   â”œâ”€â”€ hooks/           # Custom hooks
â”‚   â”œâ”€â”€ types/           # TypeScript definitions
â”‚   â”œâ”€â”€ App.tsx          # Main application
â”‚   â””â”€â”€ main.tsx         # Entry point
â”œâ”€â”€ public/
â”œâ”€â”€ index.html
â””â”€â”€ vite.config.ts       # Build configuration
âœ… Future Improvements
Store chat history in persistent database

Add markdown rendering for LLM responses

Show sources/confidence from FAISS results

Deploy backend on Render/Vercel

Add API documentation upload interface

Implement user authentication

Add rate limiting for API endpoints
